{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf gan\n",
        "!git clone https://github.com/mryanivtal/gan.git\n",
        "MAIN_DIR = './gan/src/main.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWl-7sQib5wf",
        "outputId": "509869c8-5211-4a43-ce85-0a30744259f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gan'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 109 (delta 44), reused 98 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (109/109), 101.16 KiB | 16.86 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "project_root_path = Path('drive/MyDrive/Colab Notebooks/gan')\n",
        "\n",
        "ds_path = Path('datasets')\n",
        "if not ds_path.exists():\n",
        "  # copy cats.zip to local\n",
        "  ds_path.mkdir(exist_ok=True, parents=True)\n",
        "  shutil.copy(project_root_path / Path('cats.zip'), ds_path)\n",
        "\n",
        "  # extract zip\n",
        "  with zipfile.ZipFile(ds_path / Path('cats.zip'), 'r') as zip_ref:\n",
        "      zip_ref.extractall(ds_path)\n",
        "\n",
        "  DATASET_PATH = ds_path / Path('cats')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QJk9bE-d2jK",
        "outputId": "9050d129-73c2-4ba2-871f-2ef750265a0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4DWPQ0HbyJF",
        "outputId": "48898ac9-0de3-4f8b-9458-51fb11e872f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 19 18:45:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "# Check env settings\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd gan/src; python main.py --datadir=\"../../datasets/cats\" --outdir=\"../../drive/MyDrive/Colab Notebooks/gan/output\" --lrgen=0.0005 --lrdis=0.0005 --batchsize=128 --randomseed=999 --dlworkers=2 --epochs=100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPXOc4uhiK6m",
        "outputId": "ea1fdd97-605c-4e29-ba96-eb0ae1f03007"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output path: /content/gan/src/../../drive/MyDrive/Colab Notebooks/gan/output\n",
            "Random seed: 999\n",
            "DIS_LEARNING_RATE = 0.0005\n",
            "GEN_LEARNING_RATE = 0.0005\n",
            "DIS_BETA = 0.5\n",
            "GEN_BETA = 0.5\n",
            "NUM_EPOCHS = 100\n",
            "BATCH_SIZE = 128\n",
            "DL_WORKERS = 2\n",
            "Epoch: 1, dis_loss: 1.5924091648550764, gen_loss: 6.389540410810901\n",
            "Epoch: 2, dis_loss: 0.8983235428890874, gen_loss: 4.224610724756794\n",
            "Epoch: 3, dis_loss: 1.233702611418501, gen_loss: 3.4753917551809743\n",
            "Epoch: 4, dis_loss: 1.182633477833963, gen_loss: 3.3925184357550835\n",
            "Epoch: 5, dis_loss: 1.2300500528466316, gen_loss: 3.0237868630116984\n",
            "Epoch: 6, dis_loss: 1.2812066847278225, gen_loss: 2.908417993976224\n",
            "Epoch: 7, dis_loss: 1.1912916071953312, gen_loss: 2.8407902929090683\n",
            "Epoch: 8, dis_loss: 1.219762368548301, gen_loss: 2.7139955778275766\n",
            "Epoch: 9, dis_loss: 1.1676361974208587, gen_loss: 2.8207783444273855\n",
            "Epoch: 10, dis_loss: 1.1752260036526188, gen_loss: 2.8165379099307524\n",
            "Epoch: 11, dis_loss: 1.1053184174722241, gen_loss: 2.8462365702275307\n",
            "Epoch: 12, dis_loss: 1.0739113082808833, gen_loss: 2.9813535790289603\n",
            "Epoch: 13, dis_loss: 1.0615072329678843, gen_loss: 3.1767116775435786\n",
            "Epoch: 14, dis_loss: 1.0562185039443355, gen_loss: 3.142300042413896\n",
            "Epoch: 15, dis_loss: 1.019124452144869, gen_loss: 3.177633567202476\n",
            "Epoch: 16, dis_loss: 0.9727216593680843, gen_loss: 3.2129633532416437\n",
            "Epoch: 17, dis_loss: 0.9724192874085519, gen_loss: 3.2678034161367724\n",
            "Epoch: 18, dis_loss: 0.9156448744958446, gen_loss: 3.271519822459067\n",
            "Epoch: 19, dis_loss: 0.8575874711236646, gen_loss: 3.3658950175008466\n",
            "Epoch: 20, dis_loss: 0.9807198345661163, gen_loss: 3.2225610277345105\n",
            "/content/gan/src/common_utils/torch_pil_utils.py:32: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig = plt.figure(figsize=(4., 4.))\n",
            "Epoch: 21, dis_loss: 0.9113911327815825, gen_loss: 3.104444653757157\n",
            "Epoch: 22, dis_loss: 0.9567389199810643, gen_loss: 3.216012613907937\n",
            "Epoch: 23, dis_loss: 0.8942995518445969, gen_loss: 3.179865277582599\n",
            "Epoch: 24, dis_loss: 0.9379254478600717, gen_loss: 3.213848402423243\n",
            "Epoch: 25, dis_loss: 0.9203981930209745, gen_loss: 3.246855296434895\n",
            "Epoch: 26, dis_loss: 0.8948423151046999, gen_loss: 3.3389125639392483\n",
            "Epoch: 27, dis_loss: 0.9270711526755364, gen_loss: 3.1747258070015136\n",
            "Epoch: 28, dis_loss: 0.9386509399740927, gen_loss: 3.2674749849304074\n",
            "Epoch: 29, dis_loss: 0.9034737391817954, gen_loss: 3.0812336485232077\n",
            "Epoch: 30, dis_loss: 0.9419845679113942, gen_loss: 3.116235351370227\n",
            "Epoch: 31, dis_loss: 0.9266793006850828, gen_loss: 3.0238503381129234\n",
            "Epoch: 32, dis_loss: 0.9153681176324044, gen_loss: 3.0527867146076693\n",
            "Epoch: 33, dis_loss: 0.878607502387416, gen_loss: 2.9594487249851227\n",
            "Epoch: 34, dis_loss: 0.9516165850143279, gen_loss: 2.955071893911208\n",
            "Epoch: 35, dis_loss: 0.8690920568281605, gen_loss: 3.097167395776318\n",
            "Epoch: 36, dis_loss: 0.8717864424951615, gen_loss: 3.1191551906447255\n",
            "Epoch: 37, dis_loss: 0.905777471680795, gen_loss: 3.142157349855669\n",
            "Epoch: 38, dis_loss: 0.8170199336544159, gen_loss: 3.0755989205452705\n",
            "Epoch: 39, dis_loss: 0.8373172451411525, gen_loss: 3.189306630722938\n",
            "Epoch: 40, dis_loss: 0.7758646838126644, gen_loss: 3.1279800909180797\n",
            "Epoch: 41, dis_loss: 0.7253874023595164, gen_loss: 3.3449173925384397\n",
            "Epoch: 42, dis_loss: 0.8167838944542792, gen_loss: 3.1395883653913774\n",
            "Epoch: 43, dis_loss: 0.9504176440738863, gen_loss: 3.1339207382932788\n",
            "Epoch: 44, dis_loss: 0.7886477405986478, gen_loss: 3.2868996423579033\n",
            "Epoch: 45, dis_loss: 0.6889871433377266, gen_loss: 3.2489773722425586\n",
            "Epoch: 46, dis_loss: 0.6539353937391312, gen_loss: 3.3490667362366953\n",
            "Epoch: 47, dis_loss: 0.7299633014105982, gen_loss: 3.470514162894218\n",
            "Epoch: 48, dis_loss: 0.614281898063998, gen_loss: 3.5099337466301455\n",
            "Epoch: 49, dis_loss: 0.8726517504021045, gen_loss: 3.547402947420074\n",
            "Epoch: 50, dis_loss: 0.5994854927543671, gen_loss: 3.374112544040526\n",
            "Epoch: 51, dis_loss: 0.5634771448469931, gen_loss: 3.729563593864441\n",
            "Epoch: 52, dis_loss: 0.5661013844993806, gen_loss: 3.8046092347752665\n",
            "Epoch: 53, dis_loss: 0.6654981879457351, gen_loss: 3.7958132816899206\n",
            "Epoch: 54, dis_loss: 0.6625852817969937, gen_loss: 3.6541021062481787\n",
            "Epoch: 55, dis_loss: 0.6757470078526004, gen_loss: 3.7577150838990367\n",
            "Epoch: 56, dis_loss: 0.495084363005815, gen_loss: 3.904304673594813\n",
            "Epoch: 57, dis_loss: 0.5273713896111134, gen_loss: 3.9284066384838474\n",
            "Epoch: 58, dis_loss: 0.4913716604632716, gen_loss: 4.144664413505985\n",
            "Epoch: 59, dis_loss: 0.5915740908634278, gen_loss: 4.006748188887873\n",
            "Epoch: 60, dis_loss: 0.3664218046732487, gen_loss: 4.039321962864168\n",
            "Epoch: 61, dis_loss: 1.0013483380598407, gen_loss: 3.7260520633670593\n",
            "Epoch: 62, dis_loss: 0.5189314432922871, gen_loss: 3.8487555766778607\n",
            "Epoch: 63, dis_loss: 0.5095072452339434, gen_loss: 3.8958306403890735\n",
            "Epoch: 64, dis_loss: 0.3720314280400353, gen_loss: 3.9908111518429172\n",
            "Epoch: 65, dis_loss: 0.44356180463106404, gen_loss: 4.238022147647796\n",
            "Epoch: 66, dis_loss: 0.4398922648641371, gen_loss: 4.371716632958381\n",
            "Epoch: 67, dis_loss: 0.37323768797420687, gen_loss: 4.283369238338163\n",
            "Epoch: 68, dis_loss: 0.6159810336126436, gen_loss: 4.1530704262756535\n",
            "Epoch: 69, dis_loss: 0.3506390994354602, gen_loss: 4.260886277883284\n",
            "Epoch: 70, dis_loss: 0.29245264023061723, gen_loss: 4.468461273177978\n",
            "Epoch: 71, dis_loss: 0.4239836958867888, gen_loss: 4.501404445978903\n",
            "Epoch: 72, dis_loss: 0.7770664553728795, gen_loss: 4.345114968236415\n",
            "Epoch: 73, dis_loss: 0.6832299675912626, gen_loss: 4.051947575423025\n",
            "Epoch: 74, dis_loss: 0.2987518446339715, gen_loss: 3.8838288361026394\n",
            "Epoch: 75, dis_loss: 0.342013428588548, gen_loss: 4.192953631762536\n",
            "Epoch: 76, dis_loss: 0.6557204037183716, gen_loss: 4.378603674231037\n",
            "Epoch: 77, dis_loss: 0.45495256565270886, gen_loss: 4.382361173870102\n",
            "Epoch: 78, dis_loss: 0.3507597898283312, gen_loss: 4.297013821140412\n",
            "Epoch: 79, dis_loss: 0.3427892893913292, gen_loss: 4.51467758513266\n",
            "Epoch: 80, dis_loss: 0.3660429789414329, gen_loss: 4.430820962594401\n",
            "Epoch: 81, dis_loss: 0.5292706401237557, gen_loss: 4.652132689472167\n",
            "Epoch: 82, dis_loss: 0.35227349905237076, gen_loss: 4.605701584969798\n",
            "Epoch: 83, dis_loss: 0.20332009086926137, gen_loss: 4.586991729274873\n",
            "Epoch: 84, dis_loss: 0.25650054456726196, gen_loss: 4.788744387126738\n",
            "Epoch: 85, dis_loss: 0.37752302699992735, gen_loss: 4.8436491883570145\n",
            "Epoch: 86, dis_loss: 0.25030697479603753, gen_loss: 4.9022651795418035\n",
            "Epoch: 87, dis_loss: 0.1917104222961972, gen_loss: 4.962524563074112\n",
            "Epoch: 88, dis_loss: 1.0587153807282448, gen_loss: 4.404792613379898\n",
            "Epoch: 89, dis_loss: 0.29453204091518154, gen_loss: 4.640626847743988\n",
            "Epoch: 90, dis_loss: 0.9484673834616139, gen_loss: 4.634961258980535\n",
            "Epoch: 91, dis_loss: 0.2834487779726905, gen_loss: 4.308806042517385\n",
            "Epoch: 92, dis_loss: 0.2255676470456585, gen_loss: 4.690802976008384\n",
            "Epoch: 93, dis_loss: 0.3715391842828643, gen_loss: 4.585836985418873\n",
            "Epoch: 94, dis_loss: 0.48637661836560697, gen_loss: 4.818918798719683\n",
            "Epoch: 95, dis_loss: 0.9820988819363617, gen_loss: 4.040634313418019\n",
            "Epoch: 96, dis_loss: 0.38569697803787645, gen_loss: 4.309397061024943\n",
            "Epoch: 97, dis_loss: 0.24684300556057884, gen_loss: 4.597541135164999\n",
            "Epoch: 98, dis_loss: 0.19169632360459335, gen_loss: 4.432450564638261\n",
            "Epoch: 99, dis_loss: 0.9982189406310359, gen_loss: 3.7946579980273403\n",
            "Epoch: 100, dis_loss: 0.22558855223319224, gen_loss: 4.245981083762262\n"
          ]
        }
      ]
    }
  ]
}